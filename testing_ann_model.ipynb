{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Some Test Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "\n",
    "1. Preprocess the new audio data\n",
    "2. predict the classes\n",
    "3. Invere transform your Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "extracted_features = pd.read_json('artifacts/preprocessed_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-217.355255127, 70.2233810425, -130.385269165...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-424.0981750488, 109.3407669067, -52.91952514...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-458.7911376953, 121.3841934204, -46.52066040...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-413.8998413086, 101.6637268066, -35.42945098...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-446.603515625, 113.6854095459, -52.402214050...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>[-398.5845031738, 135.5349578857, -50.72501754...</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>[-346.4742126465, 86.3481521606, -45.168571472...</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>[-303.8882446289, 111.3594512939, -45.94156646...</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>[-344.1100769043, 125.4502105713, -54.90344238...</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>[-315.6028137207, 94.8548049927, -37.222339630...</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature             class\n",
       "0     [-217.355255127, 70.2233810425, -130.385269165...          dog_bark\n",
       "1     [-424.0981750488, 109.3407669067, -52.91952514...  children_playing\n",
       "2     [-458.7911376953, 121.3841934204, -46.52066040...  children_playing\n",
       "3     [-413.8998413086, 101.6637268066, -35.42945098...  children_playing\n",
       "4     [-446.603515625, 113.6854095459, -52.402214050...  children_playing\n",
       "...                                                 ...               ...\n",
       "8727  [-398.5845031738, 135.5349578857, -50.72501754...          car_horn\n",
       "8728  [-346.4742126465, 86.3481521606, -45.168571472...          car_horn\n",
       "8729  [-303.8882446289, 111.3594512939, -45.94156646...          car_horn\n",
       "8730  [-344.1100769043, 125.4502105713, -54.90344238...          car_horn\n",
       "8731  [-315.6028137207, 94.8548049927, -37.222339630...          car_horn\n",
       "\n",
       "[8732 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "import numpy as np\n",
    "\n",
    "X=np.array(extracted_features['feature'].tolist())\n",
    "y=np.array(extracted_features['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "test_file = \"data/UrbanSound8K/audio/fold7/14524-1-0-0.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.7804196e+02  1.0086775e+02 -1.9973530e+01  3.1987238e+01\n",
      " -1.4757460e+01 -4.6162176e+00 -1.3627762e+01  1.5336634e+01\n",
      " -3.0565466e+01  1.1935386e+01 -7.0951843e+00  7.2580409e+00\n",
      " -1.3217763e+01  1.4461652e+01 -1.2319299e+01  6.3985977e+00\n",
      " -1.2420040e+01  3.5379386e+00 -1.1166657e+01  6.7319460e+00\n",
      " -1.1938071e+01  5.8399754e+00  3.8301560e-01  1.1930777e+01\n",
      " -1.7704952e+00  1.0068387e+01 -1.2712942e+00  4.2633435e-01\n",
      " -8.3065748e+00  4.9413590e+00 -3.0675430e+00  1.2811356e+00\n",
      " -3.7662315e+00  3.3935826e+00 -6.3912730e+00 -6.4653718e-01\n",
      " -8.4462947e-01  1.1635895e+00 -5.4512024e+00  1.2821486e+00]\n"
     ]
    }
   ],
   "source": [
    "audio , sample_rate = librosa.load(test_file,res_type='kaiser_fast')\n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "print(mfccs_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.7804196e+02  1.0086775e+02 -1.9973530e+01  3.1987238e+01\n",
      "  -1.4757460e+01 -4.6162176e+00 -1.3627762e+01  1.5336634e+01\n",
      "  -3.0565466e+01  1.1935386e+01 -7.0951843e+00  7.2580409e+00\n",
      "  -1.3217763e+01  1.4461652e+01 -1.2319299e+01  6.3985977e+00\n",
      "  -1.2420040e+01  3.5379386e+00 -1.1166657e+01  6.7319460e+00\n",
      "  -1.1938071e+01  5.8399754e+00  3.8301560e-01  1.1930777e+01\n",
      "  -1.7704952e+00  1.0068387e+01 -1.2712942e+00  4.2633435e-01\n",
      "  -8.3065748e+00  4.9413590e+00 -3.0675430e+00  1.2811356e+00\n",
      "  -3.7662315e+00  3.3935826e+00 -6.3912730e+00 -6.4653718e-01\n",
      "  -8.4462947e-01  1.1635895e+00 -5.4512024e+00  1.2821486e+00]]\n"
     ]
    }
   ],
   "source": [
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40)\n"
     ]
    }
   ],
   "source": [
    "print(mfccs_scaled_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"artifacts/audio_classification.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 290ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(mfccs_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drilling'], dtype='<U16')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_class = labelencoder.inverse_transform(predicted_classes)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioclf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
